{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "from torchsummary import summary\n",
    "import torch as t\n",
    "from torchvision import models\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3345496d64f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "list[map(id, model.fc.parameters())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,181,642\n",
      "Trainable params: 11,181,642\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 42.65\n",
      "Estimated Total Size (MB): 106.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 224, 224),device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with SummaryWriter() as w:\n",
    "#     w.add_graph(model,input_to_model=t.rand(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: conv1.weight\n",
      "key: bn1.weight\n",
      "key: bn1.bias\n",
      "key: bn1.running_mean\n",
      "key: bn1.running_var\n",
      "key: bn1.num_batches_tracked\n",
      "key: layer1.0.conv1.weight\n",
      "key: layer1.0.bn1.weight\n",
      "key: layer1.0.bn1.bias\n",
      "key: layer1.0.bn1.running_mean\n",
      "key: layer1.0.bn1.running_var\n",
      "key: layer1.0.bn1.num_batches_tracked\n",
      "key: layer1.0.conv2.weight\n",
      "key: layer1.0.bn2.weight\n",
      "key: layer1.0.bn2.bias\n",
      "key: layer1.0.bn2.running_mean\n",
      "key: layer1.0.bn2.running_var\n",
      "key: layer1.0.bn2.num_batches_tracked\n",
      "key: layer1.1.conv1.weight\n",
      "key: layer1.1.bn1.weight\n",
      "key: layer1.1.bn1.bias\n",
      "key: layer1.1.bn1.running_mean\n",
      "key: layer1.1.bn1.running_var\n",
      "key: layer1.1.bn1.num_batches_tracked\n",
      "key: layer1.1.conv2.weight\n",
      "key: layer1.1.bn2.weight\n",
      "key: layer1.1.bn2.bias\n",
      "key: layer1.1.bn2.running_mean\n",
      "key: layer1.1.bn2.running_var\n",
      "key: layer1.1.bn2.num_batches_tracked\n",
      "key: layer2.0.conv1.weight\n",
      "key: layer2.0.bn1.weight\n",
      "key: layer2.0.bn1.bias\n",
      "key: layer2.0.bn1.running_mean\n",
      "key: layer2.0.bn1.running_var\n",
      "key: layer2.0.bn1.num_batches_tracked\n",
      "key: layer2.0.conv2.weight\n",
      "key: layer2.0.bn2.weight\n",
      "key: layer2.0.bn2.bias\n",
      "key: layer2.0.bn2.running_mean\n",
      "key: layer2.0.bn2.running_var\n",
      "key: layer2.0.bn2.num_batches_tracked\n",
      "key: layer2.0.downsample.0.weight\n",
      "key: layer2.0.downsample.1.weight\n",
      "key: layer2.0.downsample.1.bias\n",
      "key: layer2.0.downsample.1.running_mean\n",
      "key: layer2.0.downsample.1.running_var\n",
      "key: layer2.0.downsample.1.num_batches_tracked\n",
      "key: layer2.1.conv1.weight\n",
      "key: layer2.1.bn1.weight\n",
      "key: layer2.1.bn1.bias\n",
      "key: layer2.1.bn1.running_mean\n",
      "key: layer2.1.bn1.running_var\n",
      "key: layer2.1.bn1.num_batches_tracked\n",
      "key: layer2.1.conv2.weight\n",
      "key: layer2.1.bn2.weight\n",
      "key: layer2.1.bn2.bias\n",
      "key: layer2.1.bn2.running_mean\n",
      "key: layer2.1.bn2.running_var\n",
      "key: layer2.1.bn2.num_batches_tracked\n",
      "key: layer3.0.conv1.weight\n",
      "key: layer3.0.bn1.weight\n",
      "key: layer3.0.bn1.bias\n",
      "key: layer3.0.bn1.running_mean\n",
      "key: layer3.0.bn1.running_var\n",
      "key: layer3.0.bn1.num_batches_tracked\n",
      "key: layer3.0.conv2.weight\n",
      "key: layer3.0.bn2.weight\n",
      "key: layer3.0.bn2.bias\n",
      "key: layer3.0.bn2.running_mean\n",
      "key: layer3.0.bn2.running_var\n",
      "key: layer3.0.bn2.num_batches_tracked\n",
      "key: layer3.0.downsample.0.weight\n",
      "key: layer3.0.downsample.1.weight\n",
      "key: layer3.0.downsample.1.bias\n",
      "key: layer3.0.downsample.1.running_mean\n",
      "key: layer3.0.downsample.1.running_var\n",
      "key: layer3.0.downsample.1.num_batches_tracked\n",
      "key: layer3.1.conv1.weight\n",
      "key: layer3.1.bn1.weight\n",
      "key: layer3.1.bn1.bias\n",
      "key: layer3.1.bn1.running_mean\n",
      "key: layer3.1.bn1.running_var\n",
      "key: layer3.1.bn1.num_batches_tracked\n",
      "key: layer3.1.conv2.weight\n",
      "key: layer3.1.bn2.weight\n",
      "key: layer3.1.bn2.bias\n",
      "key: layer3.1.bn2.running_mean\n",
      "key: layer3.1.bn2.running_var\n",
      "key: layer3.1.bn2.num_batches_tracked\n",
      "key: layer4.0.conv1.weight\n",
      "key: layer4.0.bn1.weight\n",
      "key: layer4.0.bn1.bias\n",
      "key: layer4.0.bn1.running_mean\n",
      "key: layer4.0.bn1.running_var\n",
      "key: layer4.0.bn1.num_batches_tracked\n",
      "key: layer4.0.conv2.weight\n",
      "key: layer4.0.bn2.weight\n",
      "key: layer4.0.bn2.bias\n",
      "key: layer4.0.bn2.running_mean\n",
      "key: layer4.0.bn2.running_var\n",
      "key: layer4.0.bn2.num_batches_tracked\n",
      "key: layer4.0.downsample.0.weight\n",
      "key: layer4.0.downsample.1.weight\n",
      "key: layer4.0.downsample.1.bias\n",
      "key: layer4.0.downsample.1.running_mean\n",
      "key: layer4.0.downsample.1.running_var\n",
      "key: layer4.0.downsample.1.num_batches_tracked\n",
      "key: layer4.1.conv1.weight\n",
      "key: layer4.1.bn1.weight\n",
      "key: layer4.1.bn1.bias\n",
      "key: layer4.1.bn1.running_mean\n",
      "key: layer4.1.bn1.running_var\n",
      "key: layer4.1.bn1.num_batches_tracked\n",
      "key: layer4.1.conv2.weight\n",
      "key: layer4.1.bn2.weight\n",
      "key: layer4.1.bn2.bias\n",
      "key: layer4.1.bn2.running_mean\n",
      "key: layer4.1.bn2.running_var\n",
      "key: layer4.1.bn2.num_batches_tracked\n",
      "key: fc.weight\n",
      "key: fc.bias\n"
     ]
    }
   ],
   "source": [
    "for k, v in model.state_dict().items():\n",
    "    print(\"key:\", k)\n",
    "#     print(\"v:\", v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = t.nn.Linear(in_features=512, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=False).features[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace=True)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace=True)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.9857, 0.5887, 1.0000, 0.9970, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 0.9757, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9376, 1.0000,\n",
       "        1.0000, 0.9659, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9985, 0.5092,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9921, 0.9998,\n",
       "        1.0000, 1.0000, 0.9464, 1.0000, 0.6762, 1.0000, 1.0000, 0.9974, 1.0000,\n",
       "        0.9996, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        0.9997, 1.0000, 1.0000, 1.0000, 0.9991, 0.9180, 1.0000, 0.4784, 0.9985,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = t.max(a, 1)\n",
    "b.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7, 5, 7, 0, 3, 8, 8, 7, 7, 5, 7, 3, 0, 7, 1, 6, 7, 2, 3, 2, 4, 4, 0,\n",
       "        6, 3, 3, 0, 7, 1, 1, 0, 4, 4, 2, 8, 1, 9, 0, 9, 3, 9, 5, 6, 7, 8, 3, 7,\n",
       "        0, 5, 9, 5, 9, 2, 0, 5, 0, 3, 0, 0, 9, 3, 6, 9])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考\n",
    "[一文看懂迁移学习：怎样用预训练模型搞定深度学习？](https://blog.csdn.net/cdknight_happy/article/details/74474688?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    " a =t.tensor([[7.6902e-23, 2.6775e-22, 1.5320e-20, 4.7773e-21, 3.1861e-17, 8.1055e-15,\n",
    "         7.8847e-24, 1.0000e+00, 2.0557e-25, 2.6208e-24],\n",
    "        [1.8355e-03, 2.1205e-06, 1.1575e-04, 4.0477e-03, 8.5146e-04, 7.3323e-03,\n",
    "         6.0976e-05, 9.8571e-01, 8.3079e-06, 3.7411e-05],\n",
    "        [1.6551e-05, 3.0272e-06, 2.6855e-05, 5.2939e-04, 4.1054e-01, 5.8872e-01,\n",
    "         1.1081e-04, 5.6141e-05, 3.3692e-06, 9.8376e-07],\n",
    "        [2.6940e-14, 6.6966e-14, 5.5927e-11, 2.4347e-11, 9.8878e-12, 8.4014e-10,\n",
    "         1.2205e-15, 1.0000e+00, 6.5776e-15, 5.8834e-14],\n",
    "        [9.9697e-01, 5.7051e-08, 1.8724e-12, 4.9291e-15, 1.4358e-14, 7.6165e-17,\n",
    "         1.1515e-16, 4.8195e-12, 3.0321e-03, 3.5542e-09],\n",
    "        [1.7429e-11, 2.2661e-13, 1.2961e-11, 9.9998e-01, 3.7760e-10, 1.5187e-05,\n",
    "         2.8691e-09, 1.2883e-11, 1.0352e-12, 4.3074e-14],\n",
    "        [6.6152e-32, 2.6020e-30, 1.2438e-40, 7.2139e-42, 5.1680e-42, 4.2039e-45,\n",
    "         4.2109e-37, 7.2839e-42, 1.0000e+00, 2.3706e-28],\n",
    "        [6.4454e-32, 2.9192e-29, 3.2518e-35, 5.3745e-35, 1.3308e-34, 7.3296e-39,\n",
    "         3.3466e-31, 3.2518e-36, 1.0000e+00, 5.1533e-25],\n",
    "        [3.0059e-23, 5.1156e-20, 1.1922e-22, 4.0027e-23, 1.3352e-25, 2.7945e-22,\n",
    "         2.1379e-26, 1.0000e+00, 1.1641e-29, 1.3824e-26],\n",
    "        [3.8834e-18, 3.1873e-22, 5.6483e-15, 7.6214e-18, 1.7245e-15, 3.5522e-14,\n",
    "         9.4329e-27, 1.0000e+00, 2.4706e-24, 4.5426e-27],\n",
    "        [3.1735e-07, 3.6215e-11, 1.7070e-06, 6.0138e-05, 8.7289e-06, 9.7572e-01,\n",
    "         1.7370e-09, 2.4205e-02, 6.1062e-11, 6.6825e-12],\n",
    "        [4.1642e-26, 6.0666e-23, 3.0574e-22, 6.7104e-23, 2.0004e-21, 1.9604e-21,\n",
    "         7.4770e-31, 1.0000e+00, 4.3584e-27, 1.0605e-29],\n",
    "        [2.1024e-20, 9.5774e-24, 5.7082e-19, 1.0000e+00, 1.8493e-18, 7.2997e-11,\n",
    "         3.7656e-16, 1.4012e-18, 1.3016e-21, 1.5709e-22],\n",
    "        [1.0000e+00, 3.9902e-18, 1.2266e-20, 3.8949e-26, 2.3120e-22, 3.2722e-28,\n",
    "         7.2794e-30, 2.3683e-25, 8.8301e-15, 4.9370e-21],\n",
    "        [1.0747e-32, 4.0058e-26, 2.2338e-27, 7.5715e-30, 7.7014e-27, 2.6675e-21,\n",
    "         9.8004e-35, 1.0000e+00, 9.7274e-35, 2.9343e-34],\n",
    "        [6.4460e-44, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6052e-45,\n",
    "         7.3154e-33, 7.6371e-43, 4.2039e-44, 3.3925e-27],\n",
    "        [7.1557e-05, 3.5610e-03, 7.2825e-03, 4.1259e-02, 2.5843e-03, 7.1674e-03,\n",
    "         9.3762e-01, 2.0902e-05, 3.5816e-04, 7.6275e-05],\n",
    "        [1.8781e-08, 2.9429e-11, 3.0183e-05, 8.2613e-09, 1.6740e-07, 3.4765e-07,\n",
    "         3.9683e-09, 9.9997e-01, 1.8524e-14, 1.6157e-13],\n",
    "        [3.0212e-22, 2.1950e-25, 1.0000e+00, 3.2626e-19, 1.0382e-20, 5.7465e-20,\n",
    "         4.5627e-21, 1.1378e-22, 5.8325e-25, 2.8890e-26],\n",
    "        [1.8020e-05, 1.4636e-10, 1.8947e-07, 9.6590e-01, 5.1208e-08, 3.4085e-02,\n",
    "         9.8913e-07, 7.6764e-08, 1.6264e-09, 6.4142e-11],\n",
    "        [1.3077e-18, 7.8575e-21, 1.0000e+00, 2.8817e-18, 1.0487e-18, 7.9511e-16,\n",
    "         1.2436e-16, 2.4641e-19, 1.2806e-20, 4.8347e-24],\n",
    "        [6.4769e-14, 1.4219e-12, 3.3142e-12, 6.5856e-10, 9.9998e-01, 1.4667e-13,\n",
    "         1.5138e-05, 1.1595e-18, 6.0570e-15, 9.8723e-14],\n",
    "        [3.5069e-08, 2.3707e-11, 1.3666e-09, 8.3835e-08, 1.0000e+00, 1.0129e-09,\n",
    "         2.6563e-09, 1.0705e-11, 1.3892e-07, 1.4783e-10],\n",
    "        [1.0000e+00, 3.2543e-13, 4.0974e-10, 8.4109e-16, 1.9675e-12, 1.4535e-15,\n",
    "         5.1013e-18, 6.3826e-14, 1.0483e-13, 2.6450e-15],\n",
    "        [2.1516e-22, 7.9827e-14, 5.2826e-14, 1.2984e-14, 1.6026e-22, 1.1661e-13,\n",
    "         1.0000e+00, 3.1330e-23, 6.0235e-22, 2.6018e-22],\n",
    "        [1.2388e-08, 1.0329e-09, 6.2145e-06, 9.9853e-01, 3.5753e-08, 1.4500e-03,\n",
    "         1.7459e-05, 6.9918e-08, 1.2330e-09, 2.6401e-09],\n",
    "        [8.0313e-06, 9.3443e-09, 5.0510e-02, 5.0919e-01, 5.0298e-03, 3.9625e-01,\n",
    "         1.3842e-05, 3.8999e-02, 9.1838e-09, 8.2843e-08],\n",
    "        [1.0000e+00, 2.1100e-21, 9.0828e-22, 3.1244e-29, 6.2729e-19, 1.2684e-30,\n",
    "         1.8365e-30, 1.1977e-29, 1.5797e-22, 1.5083e-24],\n",
    "        [1.0631e-16, 5.9784e-20, 2.5379e-13, 3.5082e-16, 1.0225e-14, 2.5208e-09,\n",
    "         1.9602e-19, 1.0000e+00, 3.0436e-20, 2.2297e-21],\n",
    "        [1.3712e-17, 1.0000e+00, 2.9229e-19, 1.3653e-18, 1.3365e-20, 1.9635e-18,\n",
    "         1.7342e-14, 3.3239e-15, 4.6934e-15, 8.2808e-13],\n",
    "        [2.0681e-20, 1.0000e+00, 2.1203e-24, 8.0302e-24, 5.9168e-26, 9.5933e-24,\n",
    "         2.0436e-17, 4.9512e-22, 5.2296e-19, 2.0034e-15],\n",
    "        [1.0000e+00, 1.4704e-09, 5.1232e-10, 9.7671e-12, 1.9398e-11, 1.5952e-13,\n",
    "         4.3843e-14, 4.3246e-13, 7.8810e-09, 3.8590e-11],\n",
    "        [2.0077e-07, 1.7613e-09, 9.6007e-06, 1.6543e-05, 9.9996e-01, 7.9239e-06,\n",
    "         2.0049e-06, 1.3816e-06, 7.3138e-09, 2.8159e-09],\n",
    "        [7.4190e-15, 5.8578e-17, 8.2275e-12, 2.3970e-15, 1.0000e+00, 6.5499e-15,\n",
    "         1.3078e-13, 5.4832e-18, 1.0613e-17, 1.9949e-16],\n",
    "        [1.0427e-07, 3.2600e-10, 9.9211e-01, 3.3485e-05, 7.7666e-03, 7.7891e-05,\n",
    "         7.8008e-08, 1.4948e-05, 1.6858e-08, 2.0450e-10],\n",
    "        [1.4143e-04, 4.2012e-06, 8.5681e-07, 1.6246e-06, 1.9052e-08, 3.1863e-07,\n",
    "         4.0525e-06, 2.1254e-08, 9.9984e-01, 6.6966e-06],\n",
    "        [1.3072e-38, 1.0000e+00, 1.4854e-43, 1.8217e-44, 0.0000e+00, 3.5692e-41,\n",
    "         1.0318e-30, 1.4272e-38, 2.7096e-36, 3.4154e-28],\n",
    "        [5.8919e-13, 6.3597e-14, 6.3440e-16, 1.7309e-13, 2.0618e-19, 4.4181e-18,\n",
    "         1.6357e-19, 2.3100e-16, 8.8002e-13, 1.0000e+00],\n",
    "        [9.4640e-01, 2.7185e-03, 1.0165e-05, 2.3792e-06, 4.1030e-08, 1.8304e-07,\n",
    "         1.0469e-08, 4.0013e-04, 2.4332e-05, 5.0447e-02],\n",
    "        [1.4078e-14, 9.1684e-15, 1.0288e-20, 8.0654e-19, 4.6091e-25, 5.4234e-22,\n",
    "         2.9848e-23, 3.0650e-18, 7.1601e-12, 1.0000e+00],\n",
    "        [9.0380e-02, 4.1776e-02, 2.7131e-02, 6.7617e-01, 2.9194e-02, 6.1412e-02,\n",
    "         2.3880e-02, 4.6482e-03, 1.8062e-02, 2.7349e-02],\n",
    "        [2.6716e-10, 6.9869e-09, 2.9563e-12, 9.0115e-10, 1.8514e-14, 1.1914e-13,\n",
    "         6.6444e-13, 1.3765e-11, 1.0151e-08, 1.0000e+00],\n",
    "        [9.5305e-13, 3.4257e-15, 1.0206e-11, 7.7247e-08, 1.4251e-11, 1.0000e+00,\n",
    "         2.7557e-11, 2.1203e-10, 1.5251e-12, 1.1588e-11],\n",
    "        [4.8928e-07, 2.9744e-07, 4.8052e-06, 8.3961e-05, 1.9911e-03, 5.3273e-04,\n",
    "         9.9739e-01, 1.2209e-06, 5.0828e-08, 3.0714e-07],\n",
    "        [1.3202e-15, 4.0921e-18, 3.0082e-15, 4.4252e-14, 5.1421e-15, 8.6068e-12,\n",
    "         1.9694e-19, 1.0000e+00, 9.9273e-18, 4.5088e-16],\n",
    "        [1.3525e-04, 7.0952e-05, 1.6368e-05, 2.4249e-06, 9.1567e-05, 4.3919e-08,\n",
    "         5.9087e-05, 1.9181e-08, 9.9961e-01, 9.6723e-06],\n",
    "        [2.8312e-19, 9.1893e-22, 2.2152e-18, 1.0000e+00, 4.3116e-15, 7.5066e-12,\n",
    "         1.2903e-13, 1.6374e-16, 4.3698e-18, 3.3004e-22],\n",
    "        [6.2668e-08, 4.7058e-11, 7.0757e-08, 6.9965e-09, 1.9500e-09, 2.4287e-08,\n",
    "         3.2742e-10, 1.0000e+00, 7.9743e-10, 3.2082e-12],\n",
    "        [1.0000e+00, 3.5205e-22, 1.3144e-21, 8.9486e-30, 6.9926e-22, 5.2324e-31,\n",
    "         3.0228e-32, 1.3203e-29, 1.9854e-23, 6.0335e-25],\n",
    "        [7.1009e-12, 3.5367e-15, 1.4558e-13, 2.5946e-05, 6.1082e-07, 9.9997e-01,\n",
    "         2.3779e-11, 3.5611e-08, 2.8905e-15, 1.1586e-15],\n",
    "        [3.5620e-31, 1.8407e-21, 1.0140e-33, 4.8700e-29, 2.4804e-38, 7.0558e-36,\n",
    "         1.5532e-36, 4.9899e-30, 2.4456e-26, 1.0000e+00],\n",
    "        [1.9200e-11, 1.1729e-17, 2.1019e-07, 3.2386e-15, 9.3051e-09, 1.0000e+00,\n",
    "         5.2428e-14, 1.6612e-09, 2.8573e-15, 2.2886e-16],\n",
    "        [9.3036e-09, 5.8127e-16, 5.3973e-20, 1.7189e-15, 4.3639e-22, 4.3186e-21,\n",
    "         5.8986e-23, 9.8431e-19, 1.0255e-10, 1.0000e+00],\n",
    "        [1.5047e-12, 4.9450e-12, 1.0000e+00, 1.5238e-09, 1.9577e-07, 4.4276e-11,\n",
    "         2.3384e-07, 1.1406e-13, 3.9938e-12, 5.1204e-12],\n",
    "        [9.9972e-01, 5.3179e-06, 1.2436e-06, 1.6215e-09, 1.1800e-08, 2.4863e-11,\n",
    "         8.8266e-10, 7.4941e-10, 3.5047e-06, 2.6632e-04],\n",
    "        [4.7116e-19, 1.9111e-21, 1.0804e-12, 1.1231e-18, 3.2417e-19, 1.0000e+00,\n",
    "         2.9861e-12, 7.4119e-14, 1.3381e-20, 4.6149e-21],\n",
    "        [1.0000e+00, 2.9728e-20, 1.7065e-19, 4.9482e-27, 6.2049e-20, 1.1440e-27,\n",
    "         8.4556e-30, 3.3952e-25, 9.5117e-21, 4.3699e-22],\n",
    "        [3.5220e-15, 7.4757e-18, 9.6728e-17, 9.9997e-01, 5.1101e-12, 2.5351e-05,\n",
    "         2.3561e-11, 3.0091e-13, 5.1738e-17, 1.5299e-17],\n",
    "        [9.9914e-01, 2.9685e-04, 1.7119e-07, 1.5846e-09, 8.5529e-09, 9.0441e-11,\n",
    "         2.8084e-07, 2.0799e-11, 5.6142e-04, 4.9890e-08],\n",
    "        [9.1805e-01, 4.9927e-04, 8.9842e-08, 1.8254e-07, 1.2089e-06, 3.7983e-08,\n",
    "         1.6861e-04, 2.0593e-08, 8.1011e-02, 2.7193e-04],\n",
    "        [5.9195e-16, 1.3009e-06, 6.0447e-20, 8.0327e-17, 2.5200e-22, 2.1555e-20,\n",
    "         3.3037e-20, 1.0107e-16, 1.2039e-14, 1.0000e+00],\n",
    "        [5.7709e-07, 3.1805e-09, 4.4235e-01, 4.7838e-01, 2.7259e-06, 7.8964e-02,\n",
    "         2.5315e-04, 5.0509e-05, 4.0140e-07, 1.8904e-09],\n",
    "        [1.0877e-05, 8.3611e-04, 5.9014e-04, 2.4563e-07, 1.2303e-05, 1.4665e-05,\n",
    "         9.9854e-01, 1.2751e-10, 4.0806e-08, 1.5833e-08],\n",
    "        [5.9809e-22, 1.3617e-12, 2.0096e-25, 1.6079e-21, 9.0916e-28, 2.0857e-25,\n",
    "         7.7919e-26, 1.6375e-21, 2.5534e-19, 1.0000e+00]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
